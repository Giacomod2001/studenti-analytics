import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from google.cloud import bigquery
from google.oauth2 import service_account
import traceback
import logging

# â”€â”€â”€ 1) PAGE CONFIGURATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(
    page_title="ğŸ“ Student Analytics Dashboard",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded",
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

PROJECT_ID = "laboratorio-ai-460517"
DATASET_ID = "dataset"

# â”€â”€â”€ 2) DATA DESCRIPTIONS AND ORIGINS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Display names mapping (DB name -> Human readable name)
TABLE_DISPLAY_NAMES = {
    "studenti": "Students Data",
    "studenti_churn_pred": "Dropout Prediction",
    "studenti_cluster": "Student Clustering",
    "studenti_soddisfazione_btr": "Satisfaction Analysis",
    "feature_importance_studenti": "Feature Importance",
    "report_finale_soddisfazione_studenti": "Satisfaction Report",
    "student_churn_rf": "Churn Model Details",
    "student_kmeans": "K-means Model Details"
}

TABLE_DESCRIPTIONS = {
    "studenti": "Student demographic and performance data",
    "studenti_churn_pred": "Dropout predictions with probability scores",
    "studenti_cluster": "Student segmentation via clustering",
    "studenti_soddisfazione_btr": "Student satisfaction analysis",
    "feature_importance_studenti": "Feature importance from predictive model",
    "report_finale_soddisfazione_studenti": "Complete satisfaction analysis report",
    "student_churn_rf": "Random Forest model details for dropout prediction",
    "student_kmeans": "K-means model details for behavioral clustering"
}

TABLE_ORIGINS = {
    "studenti": """**Origin:**

The `students` table collects demographic information and performance metrics for each student.
Source data comes from the university management system (student registry, grades, exams taken, etc.).
Before loading into BigQuery, a cleaning and normalization process was performed:
- Removal of duplicate records
- Standardization of date and string formats
- Calculation of new features (e.g., average grades, number of exams taken)
""",
    "studenti_churn_pred": """**Origin:**

This table contains dropout (churn) predictions generated by a **Random Forest** Machine Learning model.
**Main pipeline steps:**
1. Loading and cleaning base data from `students` and related tables.
2. Feature engineering: selection and transformation of the most relevant variables (e.g., average grades, study hours, event participation).
3. Splitting the dataset into training and test sets.
4. Training the Random Forest model (with parameter optimization via cross-validation).
5. Calculating churn probabilities for each student (`prob_churn` column) and predicted class (churn yes/no).
6. Saving results to this table, along with confidence level and predicted label.
""",
    "student_churn_rf": """**Origin:**

This table contains the details and metrics of the **Random Forest** model used to predict dropout.
Each row shows:
- A performance metric (e.g., accuracy, precision, recall) calculated on the test set.
- The optimal parameters used (number of trees, max depth, etc.).
Generated during the validation phase, after hyperparameter tuning and measuring performance on a hold-out set.
""",
    "feature_importance_studenti": """**Origin:**

This table shows the feature importance extracted from the `student_churn_rf` Random Forest model.
For each characteristic (`feature`) it includes:
- `importance_weight`: number of times the feature was selected for a split in the various trees of the model.
- `information_gain`: sum of information gained, indicating how much the feature contributed to reducing impurity.
- `coverage`: total number of examples in the dataset that passed through a node using that feature.
- `importance_percentage`: normalized weight on a [0,100] scale.
- `importance_category`: qualitative label (e.g., "Very Important", "Moderately Important", "Less Important").
This table is generated by taking the `feature_importances_` values from scikit-learn and saving them to BigQuery.
""",
    "studenti_cluster": """**Origin:**

The `student_cluster` table assigns each student to a cluster, obtained via the **K-means** algorithm.
**Main steps:**
1. Selection of significant numerical features (e.g., weekly study hours, average grades, number of absences).
2. Variable standardization (scaling) so they have mean = 0 and variance = 1.
3. Training K-means with K = 4 (number of clusters chosen via elbow method).
4. Calculation of the centroid for each cluster and assignment of the `cluster_id` label to each student.
5. Saving to this table of `cluster_id`, centroid coordinates, and distance of each student from their centroid.
""",
    "student_kmeans": """**Origin:**

This table contains the details of the **K-means (K = 4)** algorithm used for student clustering.
Includes:
- The coordinates of the centroids of each cluster.
- The inertia (sum of squared distances of points from their respective centroid) for each iteration (useful for verifying convergence).
Created during K-means training to analyze the quality of the subdivision.
""",
    "studenti_soddisfazione_btr": """**Origin:**

This table records the results of a **Boosted Tree** regression model (e.g., XGBoost) used to estimate student satisfaction levels.
**Main steps:**
1. Collection of satisfaction questionnaires (Likert scale 1-5).
2. Cleaning and recoding of responses (e.g., transformation into numerical values).
3. Creation of descriptive features (e.g., number of events attended, average grades, family income).
4. Training the Boosted Tree regression model to predict the satisfaction score.
5. Calculation of performance metrics (RÂ², RMSE) on a hold-out set.
6. Saving results to this table, with score estimates, confidence intervals, and most influential features.
""",
    "report_finale_soddisfazione_studenti": """**Origin:**

This report summarizes the student satisfaction analysis, based on the results of `student_satisfaction_btr`.
Includes:
- Distribution charts of satisfaction scores.
- Comparison between degree programs and student clusters.
- Operational suggestions to improve the student experience.
Generated automatically via a Python script that:
1. Creates various views in BigQuery.
2. Aggregates data into summary tables.
3. Produces a final PDF/HTML to share with the project team.
"""
}

# â”€â”€â”€ 3) DATA MANAGEMENT AND OPTIMIZED CACHING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@st.cache_resource
def get_bigquery_client():
    """
    Initializes and caches the BigQuery client.
    Uses cache_resource because the client is a non-serializable object (connection).
    """
    try:
        credentials_dict = dict(st.secrets)
        
        if "private_key" in st.secrets:
             credentials_dict = {
                "type": st.secrets.get("type"),
                "project_id": st.secrets.get("project_id"),
                "private_key_id": st.secrets.get("private_key_id"),
                "private_key": st.secrets.get("private_key"),
                "client_email": st.secrets.get("client_email"),
                "client_id": st.secrets.get("client_id"),
                "auth_uri": st.secrets.get("auth_uri"),
                "token_uri": st.secrets.get("token_uri"),
                "auth_provider_x509_cert_url": st.secrets.get("auth_provider_x509_cert_url"),
                "client_x509_cert_url": st.secrets.get("client_x509_cert_url"),
                "universe_domain": st.secrets.get("universe_domain")
            }
        
        credentials = service_account.Credentials.from_service_account_info(credentials_dict)
        client = bigquery.Client(credentials=credentials, project=PROJECT_ID)
        return client
    except Exception as e:
        st.error(f"Error initializing BQ client: {e}")
        logger.error(f"Error initializing BQ client: {e}")
        return None

@st.cache_data(ttl=600, show_spinner=False)
def get_tables_metadata_cached():
    """
    Retrieves table metadata.
    """
    client = get_bigquery_client()
    if not client:
        return []

    try:
        dataset_ref = client.dataset(DATASET_ID)
        tables_list = list(client.list_tables(dataset_ref))
        
        tables_info = []
        for table in tables_list:
            table_ref = dataset_ref.table(table.table_id)
            t_obj = client.get_table(table_ref)
            
            tables_info.append({
                "id": table.table_id,
                "name": TABLE_DISPLAY_NAMES.get(table.table_id, table.table_id),
                "description": TABLE_DESCRIPTIONS.get(table.table_id, "N/A"),
                "rows": t_obj.num_rows,
                "size_mb": round(t_obj.num_bytes / (1024 * 1024), 2) if t_obj.num_bytes else 0,
                "created": t_obj.created
            })
            
        return sorted(tables_info, key=lambda x: x["id"])
    except Exception as e:
        st.error(f"Error retrieving metadata: {e}")
        logger.error(f"Error metadata: {e}")
        return []

@st.cache_data(ttl=600, show_spinner=False)
def load_table_data_optimized(table_id: str):
    """
    Loads data optimizing types for Arrow/Streamlit.
    """
    client = get_bigquery_client()
    if not client:
        return pd.DataFrame()

    try:
        query = f"SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.{table_id}`"
        
        # Attempt 1: BQ Storage API (fast)
        try:
            df = client.query(query).to_dataframe()
        except Exception as e_fast:
            logger.warning(f"Fast loading failed for {table_id}: {e_fast}")
            # Attempt 2: REST API standard
            try:
                df = client.query(query).to_dataframe(create_bqstorage_client=False)
            except Exception as e_rest:
                logger.warning(f"REST loading failed for {table_id}: {e_rest}")
                # Attempt 3: Manual (slow but safe, doesn't require db-dtypes)
                try:
                    job = client.query(query)
                    rows = [dict(row) for row in job.result()]
                    df = pd.DataFrame(rows)
                except Exception as e_manual:
                    raise e_manual

        # Type optimization to reduce memory and improve Arrow compatibility
        if not df.empty:
            for col in df.select_dtypes(include=['object']).columns:
                num_unique = df[col].nunique()
                num_total = len(df)
                if num_total > 0 and num_unique / num_total < 0.5:
                    df[col] = df[col].astype('category')
                
        return df
    except Exception as e:
        st.error(f"Error loading data {table_id}: {e}")
        logger.error(f"Error loading data {table_id}: {e}")
        return pd.DataFrame()

# â”€â”€â”€ 4) UI & DESIGN SYSTEM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def inject_custom_css():
    st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap');

        html, body, [class*="css"]  {
            font-family: 'Inter', sans-serif;
        }

        .stApp {
            background-color: #f8f9fa;
        }
        
        [data-testid="stMetric"] {
            background-color: #ffffff;
            padding: 15px;
            border-radius: 10px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
            border: 1px solid #e9ecef;
        }
        
        @media (prefers-color-scheme: dark) {
            [data-testid="stMetric"] {
                background-color: #262730;
                border: 1px solid #363940;
                box-shadow: 0 2px 5px rgba(0,0,0,0.2);
            }
            .stApp {
                background-color: #0e1117;
            }
        }

        [data-testid="stSidebar"] {
            background-color: #f0f2f6;
            border-right: 1px solid #e9ecef;
        }
        @media (prefers-color-scheme: dark) {
            [data-testid="stSidebar"] {
                background-color: #1a1c24;
                border-right: 1px solid #363940;
            }
        }

        h1, h2, h3 {
            font-weight: 700;
            letter-spacing: -0.5px;
        }
        
        .block-container {
            padding-top: 2rem;
        }
        
        .stSpinner > div {
            border-top-color: #4F46E5 !important;
        }
    </style>
    """, unsafe_allow_html=True)


# â”€â”€â”€ 5) RENDERING / DATA VISUALIZATION FUNCTIONS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def apply_chart_theme(fig):
    """
    Applies a minimal, clean theme to Plotly charts.
    Focus on readability with minimal colors.
    """
    fig.update_layout(
        template="simple_white",
        font=dict(family="Inter, sans-serif", size=11, color="#1f2937"),
        title_font=dict(family="Inter, sans-serif", size=16, color="#111827"),
        paper_bgcolor="white",
        plot_bgcolor="white",
        margin=dict(l=40, r=40, t=60, b=40),
        hoverlabel=dict(
            bgcolor="white",
            font_size=11,
            font_family="Inter, sans-serif",
            bordercolor="#e5e7eb"
        ),
        showlegend=True,
        legend=dict(
            bgcolor="white",
            bordercolor="#e5e7eb",
            borderwidth=1
        )
    )
    # Minimal grid lines
    fig.update_xaxes(
        showgrid=True, 
        gridwidth=1, 
        gridcolor='#f3f4f6',
        showline=True,
        linewidth=1,
        linecolor='#d1d5db'
    )
    fig.update_yaxes(
        showgrid=True, 
        gridwidth=1, 
        gridcolor='#f3f4f6',
        showline=True,
        linewidth=1,
        linecolor='#d1d5db'
    )
    return fig

def render_home_dashboard(tables_info):
    """
    Main dashboard with aggregated KPIs and About section.
    """
    st.title("ğŸ“ Student Analytics Dashboard")
    
    # About Section
    st.markdown("""
    <div style="background-color: #eef2ff; padding: 20px; border-radius: 10px; border-left: 5px solid #4f46e5; margin-bottom: 25px;">
        <h4 style="color: #4f46e5; margin-top: 0;">â„¹ï¸ About this Platform</h4>
        <p style="margin-bottom: 0; color: #374151;">
            A functional MVP of a cloud-native ML platform to predict university dropout risk, 
            demonstrating data-driven retention strategies.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # KPI Cards Row
    col1, col2, col3, col4 = st.columns(4)
    
    total_rows = sum(t["rows"] for t in tables_info)
    total_size = sum(t["size_mb"] for t in tables_info)
    last_update = max([t["created"] for t in tables_info]) if tables_info else "N/A"
    if hasattr(last_update, 'strftime'):
        last_update = last_update.strftime("%d/%m/%Y")

    col1.metric("Total Datasets", len(tables_info))
    col2.metric("Total Records", f"{total_rows:,}")
    col3.metric("Data Size", f"{total_size:.1f} MB")
    col4.metric("Last Update", last_update)
    
    st.markdown("---")
    st.subheader("ğŸ“‚ Data Catalogue")
    
    # Grid layout for table cards
    cols = st.columns(3)
    for idx, t in enumerate(tables_info):
        with cols[idx % 3]:
            with st.container():
                st.markdown(f"""
                <div style="border: 1px solid #e5e7eb; border-radius: 8px; padding: 15px; height: 100%; background-color: white;">
                    <h4 style="margin-top: 0; color: #111827;">ğŸ“„ {t['name']}</h4>
                    <p style="font-size: 0.9em; color: #6b7280; height: 40px; overflow: hidden; text-overflow: ellipsis;">{t['description']}</p>
                    <div style="display: flex; justify-content: space-between; align-items: center; margin-top: 10px;">
                        <span style="background-color: #f3f4f6; padding: 2px 8px; border-radius: 4px; font-size: 0.8em; color: #374151;">{t['rows']:,} rows</span>
                        <span style="font-size: 0.8em; color: #9ca3af;">{t['size_mb']} MB</span>
                    </div>
                </div>
                """, unsafe_allow_html=True)


def create_specialized_chart(df: pd.DataFrame, table_id: str):
    """
    Creates minimal, clean specialized charts for ML tables.
    """
    NEUTRAL_COLOR = '#6b7280'  # Neutral gray
    ACCENT_COLOR = '#3b82f6'   # Clean blue
    
    if table_id == "studenti_churn_pred" and 'prob_churn' in df.columns:
        # Clean bar chart instead of filled histogram
        fig = go.Figure()
        
        # Create bins
        hist_data = np.histogram(df['prob_churn'], bins=20)
        
        fig.add_trace(go.Bar(
            x=hist_data[1][:-1],
            y=hist_data[0],
            marker=dict(
                color=NEUTRAL_COLOR,
                line=dict(color='white', width=2)
            ),
            name='Students'
        ))
        
        fig.update_layout(
            title="Dropout Probability Distribution",
            xaxis_title="Dropout Probability",
            yaxis_title="Number of Students",
            bargap=0.1
        )
        return apply_chart_theme(fig)
    
    elif table_id == "feature_importance_studenti":
        # Clean horizontal bar chart with single color
        importance_cols = [col for col in df.columns if 'importance' in col.lower() or 'peso' in col.lower() or 'percentuale' in col.lower()]
        feature_col = next((col for col in df.columns if 'feature' in col.lower() or 'caratteristica' in col.lower()), df.columns[0])
        
        if importance_cols:
            df_sorted = df.sort_values(by=importance_cols[0], ascending=True).tail(15)
            
            fig = go.Figure()
            fig.add_trace(go.Bar(
                y=df_sorted[feature_col],
                x=df_sorted[importance_cols[0]],
                orientation='h',
                marker=dict(
                    color=ACCENT_COLOR,
                    line=dict(color='white', width=1)
                ),
                name='Importance'
            ))
            
            fig.update_layout(
                title="Top 15 Features by Importance",
                xaxis_title="Importance Score",
                yaxis_title="Feature",
                height=500
            )
            return apply_chart_theme(fig)
    
    elif table_id == "studenti_cluster":
        # Simple bar chart with neutral colors
        cluster_col = next((col for col in df.columns if 'cluster' in col.lower()), None)
        if cluster_col:
            cluster_counts = df[cluster_col].value_counts().sort_index().reset_index()
            cluster_counts.columns = ['Cluster', 'Count']
            
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=cluster_counts['Cluster'].astype(str),
                y=cluster_counts['Count'],
                marker=dict(
                    color=NEUTRAL_COLOR,
                    line=dict(color='white', width=2)
                ),
                name='Students'
            ))
            
            fig.update_layout(
                title="Student Distribution by Cluster",
                xaxis_title="Cluster ID",
                yaxis_title="Number of Students"
            )
            return apply_chart_theme(fig)
    
    return None


def render_table_inspection(df: pd.DataFrame, table_info: dict):
    """
    Detailed visualization of a single table.
    """
    # Header with metadata
    col_head_1, col_head_2 = st.columns([3, 1])
    with col_head_1:
        st.title(f"ğŸ“„ {table_info['name']}")
        st.markdown(f"*{table_info['description']}*")
    with col_head_2:
        st.download_button(
            label="ğŸ“¥ Export CSV",
            data=df.to_csv(index=False).encode("utf-8"),
            file_name=f"{table_info['name']}.csv",
            mime="text/csv",
            use_container_width=True
        )
    
    # Quick metrics
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("Rows", f"{len(df):,}")
    m2.metric("Columns", len(df.columns))
    missing_pct = round(df.isna().sum().sum() / (len(df) * len(df.columns)) * 100, 2) if not df.empty else 0
    m3.metric("Missing Values", f"{missing_pct}%")
    mem_mb = round(df.memory_usage(deep=True).sum() / (1024 * 1024), 2) if not df.empty else 0
    m4.metric("Memory", f"{mem_mb} MB")
    
    st.markdown("---")

    # Tabs
    tab_data, tab_stats, tab_info = st.tabs(["ğŸ” Explore Data", "ğŸ“Š Statistics & Charts", "â„¹ï¸ Info & Origin"])
    
    with tab_data:
        # Quick filters
        with st.expander("ğŸ” Advanced Filters", expanded=False):
            col_f1, col_f2 = st.columns([1, 2])
            with col_f1:
                search = st.text_input("Search text", placeholder="Type to filter...")
            with col_f2:
                cols = st.multiselect("Visible columns", df.columns.tolist(), default=df.columns.tolist()[:8])
        
        df_view = df.copy()
        if search:
            mask = df_view.astype(str).apply(lambda x: x.str.contains(search, case=False, na=False)).any(axis=1)
            df_view = df_view[mask]
        
        if cols:
            st.dataframe(df_view[cols].head(200), use_container_width=True, height=500)
            st.caption(f"Showing {min(200, len(df_view))} of {len(df_view)} filtered rows.")
        else:
            st.warning("Select at least one column.")

    with tab_stats:
        # Check for specialized chart
        specialized_chart = create_specialized_chart(df, table_info["id"])
        
        if specialized_chart:
            st.plotly_chart(specialized_chart, use_container_width=True)
            st.markdown("---")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        col_viz_1, col_viz_2 = st.columns([1, 3])
        
        with col_viz_1:
            st.markdown("#### âš™ï¸ Configuration")
            chart_type = st.selectbox("Chart Type", ["Histogram", "Box Plot", "Scatter", "Bar Chart", "Heatmap"], index=0)
            
            x_axis = st.selectbox("X Axis", df.columns)
            y_axis = st.selectbox("Y Axis", [None] + numeric_cols) if chart_type != "Heatmap" else None
            color_dim = st.selectbox("Color", [None] + df.columns.tolist()) if chart_type != "Heatmap" else None
            
        with col_viz_2:
            try:
                fig = None
                # Default neutral color
                default_color = '#6b7280'
                
                if chart_type == "Histogram":
                    fig = px.histogram(
                        df, x=x_axis, y=y_axis, color=color_dim, 
                        title=f"Distribution of {x_axis}",
                        color_discrete_sequence=[default_color] if not color_dim else None
                    )
                elif chart_type == "Box Plot":
                    fig = px.box(
                        df, x=x_axis, y=y_axis, color=color_dim, 
                        title=f"Box Plot {x_axis}",
                        color_discrete_sequence=[default_color] if not color_dim else None
                    )
                elif chart_type == "Scatter":
                    fig = px.scatter(
                        df, x=x_axis, y=y_axis, color=color_dim, 
                        title=f"Scatter {x_axis} vs {y_axis}",
                        color_discrete_sequence=[default_color] if not color_dim else None
                    )
                elif chart_type == "Bar Chart":
                    if len(df) > 1000 and y_axis:
                        df_agg = df.groupby(x_axis)[y_axis].mean().reset_index()
                        fig = px.bar(
                            df_agg, x=x_axis, y=y_axis, 
                            color=color_dim if color_dim in df_agg else None, 
                            title=f"Average {y_axis} by {x_axis}",
                            color_discrete_sequence=[default_color] if not color_dim or color_dim not in df_agg else None
                        )
                    else:
                        fig = px.bar(
                            df, x=x_axis, y=y_axis, color=color_dim, 
                            title=f"Bar Chart {x_axis}",
                            color_discrete_sequence=[default_color] if not color_dim else None
                        )
                elif chart_type == "Heatmap":
                    if len(numeric_cols) > 1:
                        corr = df[numeric_cols].corr()
                        # Minimal heatmap with white-to-blue scale
                        fig = px.imshow(
                            corr, 
                            text_auto='.2f', 
                            title="Correlation Matrix", 
                            color_continuous_scale=['#ffffff', '#3b82f6'],
                            aspect="auto"
                        )
                    else:
                        st.info("Need at least 2 numerical columns for Heatmap.")

                if fig:
                    fig = apply_chart_theme(fig)
                    st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"Error creating chart: {e}")

    with tab_info:
        st.markdown("### ğŸ“– Origin and Description")
        origin_text = TABLE_ORIGINS.get(table_info["id"], "No detailed information available.")
        st.markdown(origin_text)

# â”€â”€â”€ 6) MAIN APP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    inject_custom_css()
    
    # Sidebar Navigation
    st.sidebar.title("ğŸ“ Analytics")
    st.sidebar.caption("v2.0 | BigQuery Powered")
    
    # Connection status (hidden if OK for cleanliness, shown only on error or request)
    client = get_bigquery_client()
    if not client:
        st.error("âŒ Critical error: Unable to connect to BigQuery.")
        st.stop()
        
    # Load metadata (cached)
    with st.spinner("Loading catalogue..."):
        tables_info = get_tables_metadata_cached()
    
    if not tables_info:
        st.warning("No tables found.")
        st.stop()
        
    # Navigation Menu
    st.sidebar.markdown("### ğŸ§­ Navigation")
    options = ["ğŸ  Home Dashboard"] + [f"ğŸ“„ {t['name']}" for t in tables_info]
    selection = st.sidebar.radio("", options, label_visibility="collapsed")
    
    st.sidebar.markdown("---")
    with st.sidebar.expander("âš™ï¸ Settings"):
        if st.button("ğŸ”„ Clear Cache"):
            st.cache_data.clear()
            st.cache_resource.clear()
            st.rerun()
        st.info("Cache TTL: 10 min")
        
    # Routing
    if selection == "ğŸ  Home Dashboard":
        render_home_dashboard(tables_info)
    else:
        # Extract table name
        table_name = selection.split("ğŸ“„ ")[1]
        current_info = next((t for t in tables_info if t["name"] == table_name), None)
        
        if current_info:
            with st.spinner(f"Loading data {table_name}..."):
                df = load_table_data_optimized(current_info["id"])
                
            if not df.empty:
                render_table_inspection(df, current_info)
            else:
                st.warning(f"Table {table_name} is empty or unable to load.")

if __name__ == "__main__":
    main()
